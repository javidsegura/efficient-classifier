{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> DYNAMIC MALWARE CLASSIFICATION</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Supervised, classification, multi-class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CONTENT INDEX\n",
        "\n",
        "1. SET-UP\n",
        "  - Report\n",
        "2. EDA\n",
        "  - Data types\n",
        "  - Descriptive statistics\n",
        "    - Plots, summary statistics \n",
        "  - Relationships between variables \n",
        "  - other...\n",
        "  - Conclusion \n",
        "3. DATA SPLITTING\n",
        "4. Data preprocessing\n",
        "  - Missing data analysis\n",
        "  - Outlier detection analysis\n",
        "  - Data imputing\n",
        "  - Class imbalance\n",
        "5. FEATURE ANALYSIS\n",
        "  - Feature transformation\n",
        "  - Feature selection\n",
        "6. MODELLING\n",
        "  - Non-optimized training\n",
        "  - Optimized training\n",
        "  - Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szqv1Y9Edzc5"
      },
      "source": [
        "# 0. Basic Set-Up and General info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: there are a lot of non-used imports (to be removed at the end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utilities_functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If u make a change to utilities_function u may need to restart the kernel to use the latest versions. This is too tedious. There must be another way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
        "                              BaggingClassifier)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "from boruta import BorutaPy\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Documentation Standarization\n",
        "Follow the following guidelines to make sure our document is consistent and easier to undestand\n",
        "- All constant should be writte in full capitall letters (e.g: MY_CONSTANT). Notebook-level constants should be written in the cell assigned to it (see below)\n",
        "- Every new major section (EDA, Feature engineering) should be written with '# My title'#\n",
        "- Subsequent sections should use '##', '###' or '####' hierarchacically\n",
        "- At the beginning of each major section write a content index with the content included in that section (see 'feature engineering' section as an example)\n",
        "- Please write paragraphs before and after each cell explain what u are about to do and the conclusions, correspondingly. Do not assume they are too obvious.\n",
        "- Avoid excessive ChatGPT-originated comments\n",
        "- Avoid writing more than 20 lines per code cell (exceptions for subroutines, which should be written in utilitied_functions.py)\n",
        "- Ideally, add a \"Questions\" and \"Things to be done\" section in each major sections where u write about futher iterations u want to do (while sharing in with the rest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path =\"./dataset/dynamic_dataset.csv\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "F0L2m8yFXhJ9",
        "outputId": "c94d1d43-6998-486d-d0ea-8b643d64efa6"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.rename(columns={\"reboot\": \"Reboot\"}, inplace=True) # consistency with other features' names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TspwPmuXrwg",
        "outputId": "ba126ff5-a264-4606-8b04-9716dc7a0ddf"
      },
      "outputs": [],
      "source": [
        "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook-level constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_STATE = 99\n",
        "ONLY_NUMERICAL_COLUMNS = df.select_dtypes(include='number')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Description of our features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each of our entries in the dataset we have a feature describing the state of the (operating) system under which the malware was running. Here is an intial description for each of them.\n",
        "Please access this document for a complete problem context description: https://docs.google.com/document/d/1yH9gvnJVSH9GLv9ATQ5JQWA2z8Jy4umxxRfMF-y2fiU/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we conduct an Exploratory Data Analysis (EDA) on the dynamic malware dataset to gain initial insights into the structure, distribution, and quality of the data prior to modeling. The dataset includes behavioral features extracted from Android applications, along with labels indicating their respective malware categories. Understanding the composition of the dataset, such as class imbalance, feature correlations, and the presence of outliers, is crucial to ensure robust preprocessing, informed feature engineering, and  the success of machine learning classifiers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SUGGESTIONS FOR IMPROVEMENTS\n",
        "- Cluster analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Type Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the data type distribution\n",
        "dtype_counts = df.dtypes.value_counts()\n",
        "dtype_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that most columns are numerical. Lets gets to see which are the variables that are of type object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_onlyCols = df.select_dtypes(include=[\"object\"]).columns\n",
        "df_onlyCols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28_glozSPDm7"
      },
      "source": [
        "## Histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WVSB5cgoYRDr",
        "outputId": "6da84feb-1032-4185-b3e6-de73e05279df"
      },
      "outputs": [],
      "source": [
        "# Select only numerical features\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Define number of rows and columns for subplots\n",
        "num_features = len(numerical_cols)\n",
        "cols = 4  # Number of columns per row\n",
        "rows = math.ceil(num_features / cols)  # Calculate required rows\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, rows * 4))\n",
        "axes = axes.flatten()  # Flatten to easily iterate\n",
        "\n",
        "# Plot histograms\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    sns.histplot(df[col], bins=30, kde=True, ax=axes[i])  # kde=True for smooth curve\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# Remove empty subplots\n",
        "for i in range(num_features, len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see most distributions tend to be right-skewed and only a small portion follows a normal distribution. This right-skewness will be dealt in feature-engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YDO2OqktbPDN",
        "outputId": "59795112-1aaf-4e5d-99fb-999c1b58b662"
      },
      "outputs": [],
      "source": [
        "# Select only numerical features\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Define number of rows and columns for subplots\n",
        "num_features = len(numerical_cols)\n",
        "cols = 4  # Number of columns per row\n",
        "rows = math.ceil(num_features / cols)  # Calculate required rows\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(16, rows * 4))\n",
        "axes = axes.flatten()  # Flatten to easily iterate\n",
        "\n",
        "# Plot boxplots\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    sns.boxplot(x=df[col], ax=axes[i])  # Boxplot for each feature\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# Remove empty subplots\n",
        "for i in range(num_features, len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDW_CStuioNs"
      },
      "source": [
        "## Numerical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnC_-AYbitFA"
      },
      "source": [
        "Seemed to be grouped by prefixes: Memory, Network, Battery, Logcat, Process y API.\n",
        "\n",
        "According to dataset authors to capture how various malware families and categories behave at runtime, the analysis relies on six distinct sets of features obtained after executing each sample within a controlled emulated environment. These feature groups offer a comprehensive view of the malware's dynamic activity.\n",
        "\n",
        "This categories appear before the first _ in every feature label and are defined as:\n",
        "\n",
        "\n",
        "\"Memory: Memory features define activities performed by malware by utilizing memory.\n",
        "\n",
        "API: Application Programming Interface (API) features delineate the communication between two applications.\n",
        "\n",
        "Network: Network features describe the data transmitted and received between other devices in the network. It indicates foreground and background network usage.\n",
        "\n",
        "Battery: Battery features describe the access to battery wakelock and services by malware.\n",
        "\n",
        "Logcat: Logcat features write log messages corresponding to a function performed by malware.\n",
        "\n",
        "Process: Process features count the interaction of malware with total number of processes.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raKBvgK5ircs",
        "outputId": "6109fdf7-3a42-4496-a39b-f34bfe204c1b"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "# Grouping based on the first prefix before \"_\"\n",
        "prefix_groups = defaultdict(list)\n",
        "\n",
        "for col in numeric_cols:\n",
        "    prefix = col.split(\"_\")[0]  # Get the first word before the underscore\n",
        "    prefix_groups[prefix].append(col)\n",
        "\n",
        "for prefix, columns in prefix_groups.items():\n",
        "    print(f\"\\n {prefix} ({len(columns)} features):\")\n",
        "    for col in columns:\n",
        "        print(f\"  - {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv7LWIIU5X5i"
      },
      "source": [
        "## Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "gA-v2L6x5ImZ",
        "outputId": "e7b19c28-c316-4b5a-eec7-90ee38c6dd0b"
      },
      "outputs": [],
      "source": [
        "#Statistical summary for categorical features\n",
        "df.describe(include=[\"object\", \"category\", \"bool\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJbNriVFrRYE",
        "outputId": "2935f3d0-a88b-4bd4-8b98-f4c76a641092"
      },
      "outputs": [],
      "source": [
        "print(df[['Hash', 'Category', 'Family']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBWBDyuc4q47"
      },
      "source": [
        "Hash: unique identifier that represents each malware sample. <<<>>>THIS IS PROBABLY WRONG<<<>>>\n",
        "\n",
        "Category: general classification of the malware sample based on its behavior.\n",
        "\n",
        "Family: more fine-grained grouping of malware based on its codebase or origin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC5leffBsW5W"
      },
      "source": [
        "For hash, it will first be checked if the same malware before and after reboot contains the same hash value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ep2R1vwzRyy",
        "outputId": "3048de1d-c0cd-437d-9044-68a3ed1c3fc3"
      },
      "outputs": [],
      "source": [
        "# Count how many times each hash appears in 'before' and 'after'\n",
        "hash_reboot_counts = df.groupby(['Hash', 'reboot']).size().unstack(fill_value=0)\n",
        "\n",
        "# Hashes in both with exactly one in each\n",
        "hashes_with_one_each = hash_reboot_counts[\n",
        "    (hash_reboot_counts['before'] == 1) & (hash_reboot_counts['after'] == 1)\n",
        "].index\n",
        "\n",
        "# Hashes in both but with extra rows\n",
        "hashes_in_both_but_not_clean = hash_reboot_counts[\n",
        "    (hash_reboot_counts['before'] > 0) &\n",
        "    (hash_reboot_counts['after'] > 0) &\n",
        "    ~((hash_reboot_counts['before'] == 1) & (hash_reboot_counts['after'] == 1))\n",
        "].index\n",
        "\n",
        "# Total unique hashes\n",
        "total_unique_hashes = df['Hash'].nunique()\n",
        "\n",
        "# Hashes in only one reboot condition\n",
        "hashes_in_one_condition = hash_reboot_counts[\n",
        "    (hash_reboot_counts['before'] == 0) | (hash_reboot_counts['after'] == 0)\n",
        "]\n",
        "\n",
        "# Only once in one reboot condition\n",
        "only_once_in_one = hashes_in_one_condition[\n",
        "    (hashes_in_one_condition['before'] == 1) | (hashes_in_one_condition['after'] == 1)\n",
        "]\n",
        "\n",
        "# More than once in one reboot condition\n",
        "more_than_once_in_one = hashes_in_one_condition[\n",
        "    ((hashes_in_one_condition['before'] > 1) & (hashes_in_one_condition['after'] == 0)) |\n",
        "    ((hashes_in_one_condition['after'] > 1) & (hashes_in_one_condition['before'] == 0))\n",
        "]\n",
        "\n",
        "# Split those into counts\n",
        "more_than_once_in_before = more_than_once_in_one[more_than_once_in_one['before'] > 1]\n",
        "more_than_once_in_after = more_than_once_in_one[more_than_once_in_one['after'] > 1]\n",
        "\n",
        "# --- PRINT RESULTS ---\n",
        "print(f\"Hashes with EXACTLY one row in BOTH before and after: {len(hashes_with_one_each)}\")\n",
        "print(f\"Hashes in BOTH, BUT with extra rows: {len(hashes_in_both_but_not_clean)}\")\n",
        "\n",
        "print(f\"\\nHashes in ONLY ONE reboot condition:\")\n",
        "print(f\"• Appearing ONLY ONCE: {len(only_once_in_one)}\")\n",
        "print(f\"• Appearing MORE THAN ONCE: {len(more_than_once_in_one)}\")\n",
        "print(f\"   - More than once in BEFORE: {len(more_than_once_in_before)}\")\n",
        "print(f\"   - More than once in AFTER: {len(more_than_once_in_after)}\")\n",
        "\n",
        "print(f\"\\nTotal breakdown:\")\n",
        "print(f\"• In BOTH (any): {len(hashes_with_one_each) + len(hashes_in_both_but_not_clean)}\")\n",
        "print(f\"• In ONLY ONE reboot: {len(hashes_in_one_condition)}\")\n",
        "print(f\"• TOTAL unique hashes: {total_unique_hashes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2IGnd2izsOY"
      },
      "source": [
        "A total of 19,169 hashes appear exactly once in both before and after conditions. These are highly reliable for paired  comparisons, ideal for understanding how reboot affects malware behavior.\n",
        "\n",
        "\n",
        "There are 158 hashes that appear in both reboot states but not exactly once in each. These extra instances may come from inconsistencies in data capture like multiple logs for the same sample and should be checked.\n",
        "\n",
        "A significant portion of samples appear only in one reboot condition. This is consistent with limitations described in the original dataset paper, where some malware samples failed to execute after the reboot. However, what is curious is that some still have been logged more than once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "NzJxov9LLOGu",
        "outputId": "a0691e50-f676-4ef2-e150-166b1e96a5ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nThe Hash column is a high-cardinality feature, containing unique values for a high number of rows in the dataset.\\nIt serves as an identifier for each malware sample. Including this column in modeling\\nwould not only offer no predictive value but could also lead to overfitting or cause issues with algorithms that are\\nsensitive to high-cardinality categorical features.\\n <<<>>> J.N: may be better to focus the argumentation on ID not being useful rather than high-cardinality per se. Also write the \\n  argumentation in a text cell not in this type of comments. <<<>>>\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(columns=['Hash'])\n",
        "'''\n",
        "The Hash column is a high-cardinality feature, containing unique values for a high number of rows in the dataset.\n",
        "It serves as an identifier for each malware sample. Including this column in modeling\n",
        "would not only offer no predictive value but could also lead to overfitting or cause issues with algorithms that are\n",
        "sensitive to high-cardinality categorical features.\n",
        " <<<>>> J.N: may be better to focus the argumentation on ID not being useful rather than high-cardinality per se. Also write the \n",
        "  argumentation in a text cell not in this type of comments. <<<>>>\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kZUupRE1vx5"
      },
      "source": [
        "This research will be using both Category and Family as the target variables for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaHsU58AdvlN"
      },
      "source": [
        "## Reboot Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ymeBe4fKdNi",
        "outputId": "ce478b18-ff6a-4720-f19c-e5ecabfbbbbb"
      },
      "outputs": [],
      "source": [
        "print(df[\"reboot\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8hkdL2SHVe"
      },
      "source": [
        "The imbalance observed in the dataset, with 28,380 samples collected before reboot and only 25,059 after reboot, is explained by limitations found during the dynamic analysis. The authors of the dataset note that \"there was no entry point in some Android malware samples and some Android malware samples stopped abruptly.\" This means that certain malware applications either failed to launch or terminated unexpectedly during execution, preventing the collection of dynamic behavior data, particularly after the reboot phase.\n",
        "\n",
        "Additionally, the study highlights another critical limitation: \"the dynamic analysis is performed in an emulator. Some malware samples are able to detect the emulated environment and are not executed.\" This behavior reflects common anti-analysis techniques used by sophisticated malware, which can detect when they are running in a sandbox or emulator and intentionally suspend their malicious actions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<<<>>>THIS ANALYSIS IS SUPER GOOD (you can delete this comment)<<<>>>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuIT6CKgeqcZ"
      },
      "source": [
        "The displayed features are the top 10  most affected by reboot showing a clear reboot-sensitive behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "i9p8S9woa19A",
        "outputId": "7c14fef2-103d-40a4-85e0-50c138fdb448"
      },
      "outputs": [],
      "source": [
        "#Category distribution across reboot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df, x='Category', hue='reboot')\n",
        "plt.title(\"Malware Categories by Reboot Condition\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWwaTM_JeoWk"
      },
      "source": [
        "To identify which numeric features are most influenced by the reboot condition, the dataset will be grouped by the reboot variable, separating entries collected before and after the device reboot. Within each group, the mean of every numeric feature will be computed, allowing for the comparison of average behavior across both states.\n",
        "\n",
        "A new column labeled 'diff' was then added, representing the difference between the mean values after and before the reboot for each feature. A positive value indicates that the feature increased after reboot, while a negative value shows it decreased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "jG1RQO7AcIWG",
        "outputId": "00489ed7-d243-4fae-d577-849381abbca2"
      },
      "outputs": [],
      "source": [
        "reboot_means = df.groupby('reboot').mean(numeric_only=True).T\n",
        "reboot_means['diff'] = reboot_means['after'] - reboot_means['before']\n",
        "reboot_means_sorted = reboot_means.sort_values(by='diff', ascending=False)\n",
        "\n",
        "reboot_means_sorted.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7cm_Z81fWqq"
      },
      "source": [
        "The results reveal that several features show clear shifts after reboot. Specially, network-related features such as Network_TotalReceivedBytes and Network_TotalTransmittedBytes demonstrate significant increases, suggesting that some malware types intensify data transmission once the device has rebooted. Memory features like Memory_SharedClean, Memory_HeapSize, and Memory_HeapAlloc also show increased values after reboot, indicating greater memory use or altered memory management after reboot.\n",
        "This shows that the reboot condition plays an important role in runtime behavior and should be treated as an important factor in exploratory analysis and modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Family"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#How many categories each family belongs to\n",
        "df.groupby(\"Family\")[\"Category\"].nunique().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Almost every family is either unknown or unique\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <<<Error: NameError: name 'family_to_category' is not defined>>> (this Irina's code; copied from Argentinan guy's notebook)\n",
        "# multi_cat_families = family_to_category[family_to_category > 1]\n",
        "# print(f\"Number of families mapping to multiple categories: {len(multi_cat_families)}\")\n",
        "# print(multi_cat_families)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is only one Family that maps to multiple categories, and is the placeholder unknown.\n",
        "\n",
        "The following code displays how many samples with unknown family labels belong to each malware category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df[\"Family\"] == \"<unknown>\"][\"Category\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Count unique families per category\n",
        "family_amount = df.groupby(\"Category\")[\"Family\"].nunique()\n",
        "\n",
        "# Step 2: Total number of instances per category\n",
        "total_per_category = df[\"Category\"].value_counts()\n",
        "\n",
        "# Step 3: Count how many of those are <unknown> per category\n",
        "unknown_amount = df[df[\"Family\"] == \"<unknown>\"][\"Category\"].value_counts()\n",
        "\n",
        "# Step 4: Combine all stats into a summary table\n",
        "summary_df = pd.DataFrame({\n",
        "    \"Family_amount\": family_amount,\n",
        "    \"Total_category\": total_per_category,\n",
        "    \"Unknown_amount\": unknown_amount\n",
        "}).fillna(0).astype({\"Unknown_amount\": int})\n",
        "\n",
        "# Step 5: Calculate percentage of unknowns per category\n",
        "summary_df[\"%_Unknown\"] = (summary_df[\"Unknown_amount\"] / summary_df[\"Total_category\"] * 100).round(2)\n",
        "\n",
        "# Reorder columns for readability\n",
        "summary_df = summary_df[[\"Family_amount\", \"Total_category\", \"Unknown_amount\", \"%_Unknown\"]]\n",
        "\n",
        "# Display the summary\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unknown_count = (df[\"Family\"] == \"<unknown>\").sum()\n",
        "print(f\"Number of rows with Family == '<unknown>': {unknown_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the analysis of family distribution across categories:\n",
        "\n",
        "The Adware category stands out with zero instances labeled as <unknown> and a balanced distribution across 43 families. This makes it a strong candidate for modeling.\n",
        "\n",
        "In contrast, Zero_Day and No_Category The categories Zero_Day and No_Category exhibit extremely high family dispersion, with 2576 and 335 unique families. These values are significantly higher than all other categories, which generally have fewer than 50 families each.\n",
        "\n",
        "\n",
        "This suggests they function more as placeholder labels. In particular, Zero_Day likely serves as a catch-all label for unknown or uncategorized threats, making it ambiguous. In cybersecurity, this term is refered to a new unknown vulnerability, not yet classified in terms of malware behavior, this is why samples are varied. They do not seem to represent a consistent type. On the other hand, No_Category explicitly denotes a lack of category. So, including these instances would only bring noise to the training process, preventing the model from learning meaningful patterns.\n",
        "Therefore, they are excluded from the final dataset to preserve the quality and consistency of the classification task.\n",
        "\n",
        "\n",
        "Additionally, categories like FileInfector show a high percentage of <unknown> families (6.85%) despite having a small total count, raising concerns about label quality. Most other categories maintain a relatively stable level of unknowns (around 3–5%), indicating that the presence of <unknown> is manageable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA SPLITTING\n",
        "### TO BE DONE\n",
        "- Statistical analysis of this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Splitting: Category as target variable\n",
        "Originally, we will focus only on category\n",
        "\n",
        "Lets first get the X and y extracted from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category, y_category = get_X_y(df, \"Category\", [\"Family\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we continue with the split, lets advance some for the time we get to the encoding process. \n",
        "We are gonna check how many categorical variables are present in each matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reboot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53434</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53435</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53436</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53437</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53438</th>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53439 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Reboot\n",
              "0      before\n",
              "1      before\n",
              "2      before\n",
              "3      before\n",
              "4      before\n",
              "...       ...\n",
              "53434  before\n",
              "53435  before\n",
              "53436  before\n",
              "53437  before\n",
              "53438  before\n",
              "\n",
              "[53439 rows x 1 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_category.select_dtypes(include=[\"object\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also object!\n",
        "Lets get back to the splitting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((42751, 142), (5344, 142), (5344, 142), (42751,), (5344,), (5344,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_category_train, X_category_val, X_category_test, y_category_train, y_category_val, y_category_test = get_split_data(X_category, y_category, train_size=0.8, validation_size=0.1, test_size=0.1, random_state=99)\n",
        "\n",
        "X_category_train.shape, X_category_val.shape, X_category_test.shape, y_category_train.shape, y_category_val.shape, y_category_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FEATURE ENCODING\n",
        "\n",
        "#### Encoding the X matrices (one-hot encoder)\n",
        "Lets fit the X encoder for the object column (reboot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category_train_encoded, X_category_val_encoded, X_category_test_encoded = get_X_sets_encoded(X_category_train, X_category_val, X_category_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets visualize the results of the encoding..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category_train_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category_val_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category_test_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome, the X matrices are all set now. Lets finally encode the target variable (which we saw in the split process is of dtype: object)\n",
        "#### Encoding y matrix (labeller encoding) \n",
        "We know our models needs the target variable to be numerical. Lets transform this series object then!\n",
        "We will fit the encoder in the training set, and extend it to the other sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_category_train_encoded, y_category_val_encoded, y_category_test_encoded = get_y_sets_encoded(y_category_train, y_category_val, y_category_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One more time, let's visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48143     8\n",
              " 10388     0\n",
              " 11029     0\n",
              " 36609     6\n",
              " 26413    13\n",
              "          ..\n",
              " 42697    12\n",
              " 36008     6\n",
              " 46265     8\n",
              " 23587     6\n",
              " 29313     8\n",
              " Length: 42751, dtype: int64,\n",
              " '------------------------------',\n",
              " 18288    6\n",
              " 40648    6\n",
              " 8718     0\n",
              " 5961     0\n",
              " 32688    8\n",
              "         ..\n",
              " 20920    6\n",
              " 33656    3\n",
              " 32607    8\n",
              " 8923     0\n",
              " 38099    6\n",
              " Length: 5344, dtype: int64,\n",
              " '------------------------------',\n",
              " 28550    13\n",
              " 43091    12\n",
              " 8287      0\n",
              " 47969     8\n",
              " 29839     8\n",
              "          ..\n",
              " 53065     4\n",
              " 49176     5\n",
              " 30395     8\n",
              " 4491      0\n",
              " 2304      0\n",
              " Length: 5344, dtype: int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_category_train_encoded, \"-\"*30,  y_category_val_encoded, \"-\"*30, y_category_test_encoded, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FEATURE ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will take adjust the features that compose the learning inputs to our model. The correctness of this section is pivotal for proper learning by the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INDEX OF THIS SECTION:\n",
        "- Feature transformation\n",
        "- Feature engineering\n",
        "- Feature selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QUESTIONS FOR THIS SECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FEATURE TRANSFORMATION\n",
        "\n",
        "- Binning\n",
        "- Interaction terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QUESTIONS FOR THIS SUBECTION\n",
        "- Where can we do binning here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FEATURE ENGINEERING\n",
        "- Domain-specific features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: This requires further understanding of the concepts around our problem's context. This will be deferred for a second iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FEATURE SELECTION\n",
        "- Analyze correlation and low-variances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1) Eliminating low-variances features\n",
        "We will start off feature selection by analyzing the variables that have low variances. Features with low variances provide little new information for the model to learn from, thus they could introduce statistical noise. Due to this reason, they should be elimanted from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will start off this analysis eliminating univariate features (i.e: the featuers with constant values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-variance features found:\n",
            "Index(['Memory_SwapPssDirty', 'Memory_AssetManagers',\n",
            "       'API_Process_android.os.Process_start',\n",
            "       'API_JavaNativeInterface_java.lang.Runtime_loadLibrary',\n",
            "       'API_WebView_android.webkit.WebView_postWebMessage',\n",
            "       'API_WebView_android.webkit.WebView_savePassword',\n",
            "       'API_WebView_android.webkit.WebView_setHttpAuthUsernamePassword',\n",
            "       'API_WebView_android.webkit.WebView_getHttpAuthUsernamePassword',\n",
            "       'API_Database_android.database.sqlite.SQLiteDatabase_create',\n",
            "       'API_DeviceInfo_android.content.pm.PackageManager_getInstallerPackageName',\n",
            "       'API_DeviceInfo_android.content.pm.PackageManager_getInstalledApplications',\n",
            "       'API_DeviceInfo_android.content.pm.PackageManager_getInstalledModules',\n",
            "       'API_DeviceInfo_android.content.pm.PackageManager_getInstalledPackages',\n",
            "       'API_Network_org.apache.http.impl.client.AbstractHttpClient_execute',\n",
            "       'API_Network_com.android.okhttp.internal.http.HttpURLConnectionImpl_getInputStream'],\n",
            "      dtype='object')\n",
            "Removed 15 features with zero variance\n"
          ]
        }
      ],
      "source": [
        "original_number_of_features = df.shape[1]\n",
        "zero_variance_features = ONLY_NUMERICAL_COLUMNS.std() == 0\n",
        "if zero_variance_features.any():\n",
        "    print(\"Zero-variance features found:\")\n",
        "    print(zero_variance_features[zero_variance_features].index)\n",
        "    df.drop(columns=zero_variance_features[zero_variance_features].index, inplace=True)\n",
        "    print(f\"Removed {original_number_of_features - df.shape[1]} features with zero variance\")\n",
        "    ONLY_NUMERICAL_COLUMNS = df.select_dtypes(include='number') #updating global variable\n",
        "else:\n",
        "    print(\"No zero-variance features found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets focus on features with too few variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "standard_deviations = ONLY_NUMERICAL_COLUMNS.std()\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.hist(standard_deviations, bins=30, edgecolor='black')\n",
        "plt.title('Distribution of Standard Deviations for Numeric Features')\n",
        "plt.xlabel('Standard Deviation')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As explained in scikit-learn's in (1.13.1 Feature selection)[https://scikit-learn.org/stable/modules/feature_selection.html], the variance threshold must be selected carefully. Too low may delete few variables, and too may be too restrictive, deleting more variables than it should."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "STD_THRESHOLD = .4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_keep = standard_deviations[(standard_deviations < STD_THRESHOLD)].index\n",
        "print(f\"Removed {len(standard_deviations) - len(cols_to_keep)} features with low variance\")\n",
        "\n",
        "df = df[cols_to_keep]\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi1pwj-9q_v5"
      },
      "source": [
        "#### 1.2) Eliminating highly correlated feature\n",
        "Highly correlated variables (multicolinearity) are problem for models because they introduce a redundancy (features that contain significantly related similar information are not bringing much new insight into the model's input) to the model that can introduce significant variance. This is due to the fact that small changes in the data may make the coefficeints of the highly correlated variables **swing** more than it should"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_correlation_matrix((17, 15), ONLY_NUMERICAL_COLUMNS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A note on the shape of this heatmap: due to the high amount of features, and the redundancy to measure the correlation between features (where corr(A,B) = corr(B,A)) we set 'np.triu(np.ones_like(corr, dtype=bool))' in the utilities functions in order to show only new non-redudant correlations between features, thus the right triangle shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well, thats a lot to digest! Lets use a non-visual methodology to confirm our initial hypothesis. We will use variance inflaction factor (VIF) along with checking manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = ONLY_NUMERICAL_COLUMNS.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(ONLY_NUMERICAL_COLUMNS.values, i) for i in range(ONLY_NUMERICAL_COLUMNS.shape[1])]\n",
        "vif_data.sort_values(by=\"VIF\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data[vif_data[\"VIF\"] >= 5].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this whenever u want to eliminate the correlated features \n",
        "# for correlated_feature in vif_data[\"Feature\"]:\n",
        "#   df.drop(columns=[correlated_feature], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets check in the heatmap if we have any multicolinearity\n",
        "corr_matrix = ONLY_NUMERICAL_COLUMNS.corr()\n",
        "\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find highly correlated feature pairs\n",
        "high_corr_pairs = (\n",
        "    upper_tri.stack()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"level_0\": \"Feature_1\", \"level_1\": \"Feature_2\", 0: \"Correlation\"})\n",
        ")\n",
        "\n",
        "# Filter correlations above 0.65 or below -0.65\n",
        "high_corr_pairs = high_corr_pairs[high_corr_pairs[\"Correlation\"].abs() > 0.7]\n",
        "high_corr_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this whenever u want to eliminate the correlated features \n",
        "# for correlated_feature in high_corr_pairs[\"Feature_1\"]:\n",
        "#   df.drop(columns=[correlated_feature], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There seems to be some clear signs of correlation. However, for the first iteration we are going to be conservative and not remove them (for now; I want to further understand hows it possible for VIF to be inf). Note however, that some of the correlations show seem to make a lot of sense (e.g: Network_TotalReceivedBytes, Network_TotalTransmittedBytes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Questions\n",
        "- What other encoders could be useful?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DATA CLEANING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INDEX FOR THIS SECTION:\n",
        "  - Handling duplicate rules\n",
        "  - Handling outliers\n",
        "  - Handling missing value \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QUESTIONS FOR THIS SECTION\n",
        "- Are there not more sophisticated outlier detections methods?\n",
        "- Ask matteo how to deal with handling outliers with many features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Handling Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No duplicate values founds, thus, no further intervetion is requried."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Handling Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets remove all outliers. Outliers are records that for a given feature its values is significanlty deviated from its centrality values (for our current example, we'll set the threshold as 3 * IQR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"API_DeviceData_android.content.ContentResolver_query\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"API_DeviceData_android.content.ContentResolver_query\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outliers_removed_df = df.copy() # Make a copy (debuggin purporses, will be set to just df eventually)\n",
        "for col in df.select_dtypes(include='number').columns:\n",
        "      Q1 = df[col].quantile(0.25)\n",
        "      Q3 = df[col].quantile(0.75)\n",
        "      IQR = Q3 - Q1\n",
        "      lower_bound = Q1 - 3 * IQR\n",
        "      upper_bound = Q3 + 3 * IQR\n",
        "      outliers_removed_df = outliers_removed_df[(outliers_removed_df[col] >= lower_bound) & (outliers_removed_df[col] <= upper_bound)]\n",
        "print(f\"Removed {len(df) - len(outliers_removed_df)} outliers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reason why we are observing such dramatic effect on the amount of eliminated outliers is due to the fact that we are being too strict expecting all rows to have not a single feature containing an outlier in its column. This is way too restrictive. We need to find a better way. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Eliminating empty values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_shape_before_elimination = df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum(df.isna().sum().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We dont have **null** values in our dataset but that does not mean we do not have **empty** values. The dataset provider may have encoded this empty values with inf, -1, or other non-sensical value (with respect to the treated column). These valuesa re referred as 'sentinel values'\n",
        " Let's look for such values, let us start first with columns of dtype = \"object\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_object = df.select_dtypes(include=[\"object\"]).columns\n",
        "columns_object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CATEGORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Category\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No_category needs to clearly be deleted as it represents missing values in that area. Zero_Day needs also to be deleted due to its high cardinality with family variably (please, someone who read the paper explain this in better detail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_amount_rows = df.shape[0]\n",
        "df = df[(df[\"Category\"] != \"No_Category\") & (df[\"Category\"] != \"Zero_Day\")]\n",
        "new_amount_rows = df.shape[0]\n",
        "print(f\"Removed {original_amount_rows - new_amount_rows} rows with empty values for category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FAMILY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Family\"].value_counts().to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see there are some families values marked with  '<unknown>'. They shall be deleted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_amount_rows = df.shape[0]\n",
        "df = df[df[\"Family\"] != \"<unknown>\"]\n",
        "new_amount_rows = df.shape[0]\n",
        "print(f\"Removed {original_amount_rows - new_amount_rows} rows with empty values for family\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "REBOOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Reboot\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Good, let's move on to numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Numerical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzing sentinel values for all possible numerical variables (fede's)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "has_inf = df.isin([np.inf, -np.inf]).any().any()\n",
        "print(\"Contains inf:\", has_inf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first .any() checks each column to see if any value in that column is True.\n",
        "\n",
        "The second .any() checks across all columns to see if any column contained a True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing missing values, conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Removed {df_shape_before_elimination - df.shape[0]} rows with empty values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to determine if a feature needs standardization or normalization\n",
        "def determine_scaling_method(feature_series):\n",
        "    \"\"\"\n",
        "    Determine whether a feature should be standardized or normalized based on its characteristics.\n",
        "    \n",
        "    Args:\n",
        "        feature_series: Pandas Series containing the feature values\n",
        "        \n",
        "    Returns:\n",
        "        str: 'standardize', 'normalize', or 'none'\n",
        "    \"\"\"\n",
        "    # Skip if all values are the same (zero variance)\n",
        "    if feature_series.std() == 0:\n",
        "        return 'none'\n",
        "    \n",
        "    # Check for outliers using IQR method\n",
        "    Q1 = feature_series.quantile(0.25)\n",
        "    Q3 = feature_series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outlier_threshold = 1.5 * IQR\n",
        "    has_outliers = ((feature_series < (Q1 - outlier_threshold)) | \n",
        "                    (feature_series > (Q3 + outlier_threshold))).any()\n",
        "    \n",
        "    # Check for normality using skewness\n",
        "    skewness = abs(stats.skew(feature_series.dropna()))\n",
        "    is_skewed = skewness > 1.0  # Threshold for significant skewness\n",
        "    \n",
        "    # Decision logic\n",
        "    if has_outliers:\n",
        "        return 'standardize'  # Standardization handles outliers better\n",
        "    elif is_skewed:\n",
        "        return 'normalize'    # Normalization is better for non-normal distributions\n",
        "    else:\n",
        "        return 'standardize'  # Default to standardization for most ML algorithms\n",
        "\n",
        "# Get numerical columns (excluding one-hot encoded columns)\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Determine scaling method for each feature\n",
        "scaling_methods = {}\n",
        "for col in numerical_cols:\n",
        "    scaling_methods[col] = determine_scaling_method(df[col])\n",
        "\n",
        "# Count of each scaling method\n",
        "method_counts = pd.Series(scaling_methods).value_counts()\n",
        "print(\"Scaling methods distribution:\")\n",
        "print(method_counts)\n",
        "\n",
        "# Create lists for each scaling method\n",
        "standardize_cols = [col for col, method in scaling_methods.items() if method == 'standardize']\n",
        "normalize_cols = [col for col, method in scaling_methods.items() if method == 'normalize']\n",
        "no_scaling_cols = [col for col, method in scaling_methods.items() if method == 'none']\n",
        "\n",
        "print(f\"\\nFeatures to standardize: {len(standardize_cols)}\")\n",
        "print(f\"Features to normalize: {len(normalize_cols)}\")\n",
        "print(f\"Features requiring no scaling: {len(no_scaling_cols)}\")\n",
        "\n",
        "# Apply the transformations\n",
        "scaler_standard = StandardScaler()\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "# Create a copy of the dataframe to avoid warnings\n",
        "df_scaled = df.copy()\n",
        "\n",
        "# Apply standardization\n",
        "if standardize_cols:\n",
        "    df_scaled[standardize_cols] = scaler_standard.fit_transform(df[standardize_cols])\n",
        "\n",
        "# Apply normalization\n",
        "if normalize_cols:\n",
        "    df_scaled[normalize_cols] = scaler_minmax.fit_transform(df[normalize_cols])\n",
        "\n",
        "# Visualize the effect of scaling on a few features\n",
        "def plot_before_after_scaling(original_df, scaled_df, features, n_features=4):\n",
        "    \"\"\"Plot histograms before and after scaling for selected features.\"\"\"\n",
        "    # Select a subset of features if there are too many\n",
        "    if len(features) > n_features:\n",
        "        features = np.random.choice(features, n_features, replace=False)\n",
        "    \n",
        "    fig, axes = plt.subplots(len(features), 2, figsize=(12, 3*len(features)))\n",
        "    \n",
        "    for i, feature in enumerate(features):\n",
        "        # Original distribution\n",
        "        sns.histplot(original_df[feature], kde=True, ax=axes[i, 0])\n",
        "        axes[i, 0].set_title(f'Original: {feature}')\n",
        "        \n",
        "        # Scaled distribution\n",
        "        sns.histplot(scaled_df[feature], kde=True, ax=axes[i, 1])\n",
        "        axes[i, 1].set_title(f'Scaled: {feature}')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot examples of standardized features\n",
        "if standardize_cols:\n",
        "    print(\"\\nExamples of standardized features:\")\n",
        "    plot_before_after_scaling(df, df_scaled, standardize_cols)\n",
        "\n",
        "# Plot examples of normalized features\n",
        "if normalize_cols:\n",
        "    print(\"\\nExamples of normalized features:\")\n",
        "    plot_before_after_scaling(df, df_scaled, normalize_cols)\n",
        "\n",
        "print(\"\\nScaling complete! The dataset is now ready for modeling.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THIS CONTAINS DATA LEAKAGE CAUSE UR FITTING TO ALL SETS THE SAME STANDARIZATION. THIS NEEDS TO BE CORRECTED. ALSO, IT IS NOT TOLERABLE TO WRITE THIS SORT OF CHATGPT COPY AND PASTE WITHOUT EXPLANATIONS. IT CLUTTERS THE CODEBASE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- QUESTION ON THIS SECTION\n",
        "   - How can statistical measurement help on the split?\n",
        "- TBD (to be done)\n",
        "   -  x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Automatic Feature Selection\n",
        "Lets briefly extend our feature selection process:\n",
        "\n",
        "### QUESTIONS\n",
        "- Can this part not be done in feature engineering?\n",
        "### TBD (things to be done)\n",
        "- Read more about boruta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### L1 regularization\n",
        "Because of L1 regularization being able to set weights 0, we can briefly train our logistic regression model with such regulartization and see which features it uses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train logistic regression model with L1 penalty\n",
        "model.fit(X_category_train_encoded, y_category_train_encoded)\n",
        "\n",
        "# Get the coefficients of the trained model\n",
        "coefficients = model.coef_\n",
        "coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictivePowerVariables = set()\n",
        "for i in range(len(coefficients[0])):\n",
        "      if abs(coefficients[0][i]) > 0:\n",
        "            predictivePowerVariables.add(X_category_train_encoded.columns[i])\n",
        "excludedVariables = set(X_category_train_encoded.columns) - predictivePowerVariables\n",
        "predictivePowerVariables, \"-\"*30, f\"Number of predictive power variables: {len(predictivePowerVariables)}\", \"-\"*30, excludedVariables, \"-\"*30, f\"Number of excluded variables: {len(excludedVariables)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### BORUTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,    \n",
        "    n_jobs=-1, # multithreading\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    max_iter=10\n",
        ")\n",
        "# Fit Boruta on your training data.\n",
        "boruta_selector.fit(X_category_train_encoded.values, y_category_train_encoded.values)\n",
        "selected_mask = boruta_selector.support_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = set(X_category_train_encoded.columns[selected_mask])\n",
        "excludedVariables = set(X_category_train_encoded.columns) - selected_features\n",
        "selected_features, \"-\"*30, f\"Number of predictive power variables: {len(selected_features)}\", \"-\"*30, excludedVariables, \"-\"*30, f\"Number of excluded variables: {len(excludedVariables)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: only execute the following cell if you want to use the results of boruta/L1 regularization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eliminate_variables_from_set([X_category_train_encoded, X_category_val_encoded, X_category_test_encoded],\n",
        "                              listOfVariables=excludedVariables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boruta said that only 61 variables were important, if that were the case the current dimensions for each set would have that nubmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_category_train_encoded.shape, X_category_val_encoded.shape, X_category_test_encoded.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Awesome, lets move on!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QUESTIONS FOR THIS SECTION\n",
        "- Can the ROC curve be used for multiclass?\n",
        "- Can a unsupervised learning algorithm (e.g: KNN) be used for this problem even tough its nature is to be supervised?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TO BE DONE FOR THIS SECTION\n",
        "- Multiple models as classifiers\n",
        "- Family as the target variable\n",
        "- Other meaningful metrics (e.g: f1) (specially for multiclass!!!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest & Decision Trees\n",
        "Instead of the originally planned logistic regression, we will be using an ensembled model first: random forest (collection of week decision trees). This model is not only likely to outperform the original choice because its nature to handle multiclass better, but also does this several orders of magnitude faster. We will add its not ensembled version too, along with gradient boosted machine\n",
        "Note we are not using not-by-default multiclass classifiers (e.g: logistic regressions, svms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-optimized fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "randomForestModel = RandomForestClassifier(random_state=RANDOM_STATE, \n",
        "                             n_estimators=100,\n",
        "                             max_depth=None,\n",
        "                             min_samples_split=2, \n",
        "                             min_samples_leaf=1)\n",
        "decisionTreeModel = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "svmModel = SVC(random_state=RANDOM_STATE,\n",
        "             kernel='rbf',\n",
        "             decision_function_shape='ovr',\n",
        "             class_weight='balanced')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "listOfModels = {\n",
        "      \"Random Forest\": randomForestModel,\n",
        "      \"Decision Tree\": decisionTreeModel,\n",
        "      \"SVM\": svmModel\n",
        "}\n",
        "\n",
        "models = {}\n",
        "for modelName, model in listOfModels.items():\n",
        "      models[modelName] = {\n",
        "            \"model\": model,\n",
        "            \"val_predictions\": \"\",\n",
        "            \"test_predictions\": \"\",\n",
        "            \"timeToFit\": \"\",\n",
        "            \"timeToMakePredictions\": \"\"\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets fit the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for classifierName, classifier in models.items():\n",
        "      start_time = time.time()\n",
        "      print(f\"Fitting {classifierName}\")\n",
        "      classifier[\"model\"].fit(X_category_train_encoded, y_category_train_encoded)\n",
        "      end_time = time.time()\n",
        "      classifier[\"timeToFit\"] = end_time - start_time\n",
        "      print(f\"\\t => Fitted {classifierName}. Took {classifier['timeToFit']} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, lets make predictions for both sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for classifierName, classifier in models.items():\n",
        "      print(f\"Predicting {classifierName}\")\n",
        "      start_time = time.time()\n",
        "      classifier[\"val_predictions\"] = classifier[\"model\"].predict(X_category_val_encoded)\n",
        "      classifier[\"test_predictions\"] = classifier[\"model\"].predict(X_category_test_encoded)\n",
        "      end_time = time.time()\n",
        "      classifier[\"timeToMakePredictions\"] = end_time - start_time\n",
        "      print(f\"\\t => Predicted {classifierName}. Took {classifier['timeToMakePredictions']} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make sure the predictions vary between holdout sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classifiers = len(models)\n",
        "fig, axes = plt.subplots(num_classifiers, 1, figsize=(8, 5*num_classifiers))\n",
        "\n",
        "if num_classifiers == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for ax, (classifierName, classifier) in zip(axes, models.items()):\n",
        "    ax.hist(classifier[\"test_predictions\"], bins=30, edgecolor='black', alpha=0.5, label='Test Predictions')\n",
        "    ax.hist(classifier[\"val_predictions\"], bins=30, edgecolor='black', alpha=0.5, label='Validation Predictions')\n",
        "    \n",
        "    ax.set_title(f'{classifierName} - Distribution of Predicted Labels')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<i> the aforeshown diagram was originally done with the sole intention to debug an error that made predictions be the same across sets. Insights may not be much meaningful after correctio, but it is worth keeping until the end of the notebook development </i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICTIONS RESULTS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for classifierName, classifier in models.items():\n",
        "      print(f\"Predictions for {classifierName}\")\n",
        "      print(f\"\\t => VALIDATION ASSESMENT:\")\n",
        "      val_acc, val_class_report, val_confusion_matrix = evaluate_classifier(y_category_val_encoded, classifier[\"val_predictions\"], display_results=True, plot_confusion_matrix=True)\n",
        "      print(f\"\\t => TEST ASSESMENT:\")\n",
        "      test_acc, test_class_report, test_confusion_matrix = evaluate_classifier(y_category_test_encoded, classifier[\"test_predictions\"], display_results=True, plot_confusion_matrix=True)\n",
        "      print(\"- - -\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3 = SVC(random_state=RANDOM_STATE,\n",
        "             kernel='rbf',\n",
        "             decision_function_shape='ovr',\n",
        "             class_weight='balanced')\n",
        "model3.fit(X_category_train_encoded, y_category_train_encoded)\n",
        "y_val_pred = model3.predict(X_category_val_encoded)\n",
        "y_test_pred = model3.predict(X_category_test_encoded)\n",
        "evaluate_classifier(y_category_val_encoded, y_val_pred, display_results=True, plot_confusion_matrix=True)\n",
        "evaluate_classifier(y_category_test_encoded, y_test_pred, display_results=True, plot_confusion_matrix=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing with grid-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note 1: the following cells took 11mins to run in an M2\n",
        "Note 2: grid-search is not a good choice for optimization (enough for an early iteration, tough). We need to get smarter using more advanced techniques (e.g: OPTUNA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "grid_search.fit(X_category_train_encoded, y_category_train_encoded)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.fit(X_category_train_encoded, y_category_train_encoded)\n",
        "y_val_pred = best_model.predict(X_category_val_encoded)\n",
        "y_test_pred = best_model.predict(X_category_test_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_classifier(y_category_val_encoded, y_val_pred, display_results=True, plot_confusion_matrix=True)\n",
        "evaluate_classifier(y_category_test_encoded, y_test_pred, display_results=True, plot_confusion_matrix=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOTEBOOK, AREAS FOR IMPROVEMENTS\n",
        "<ul> Introducing as many ML algorithms for non-predictive tasks: \n",
        "       <li> Data imputing with KNN </li>\n",
        "       <li> Cluster analysis to better understand the features </li>\n",
        "       <li> Doing PCA for features (after correlation analysis) </li>\n",
        "</ul>\n",
        "- Distilled models\n",
        "- DevOPs pipeline design\n",
        "- Deeper statistical approach to data preprocessing and EDA"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "28_glozSPDm7",
        "LDW_CStuioNs",
        "Uv7LWIIU5X5i",
        "eaHsU58AdvlN",
        "vtG27WXGd3_R",
        "vR3xQcHnLUsk",
        "tJI5MrERTBNz",
        "VDydAnW3alRu",
        "Pi1pwj-9q_v5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
